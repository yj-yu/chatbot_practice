{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 패키지 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import model as ml\n",
    "import data\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from configs import DEFINES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사전 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_OUT_PATH = './data_out/'\n",
    "data_out_path = os.path.join(os.getcwd(), DATA_OUT_PATH)\n",
    "os.makedirs(data_out_path, exist_ok=True)\n",
    "char2idx,  idx2char, vocabulary_length = data.load_vocabulary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, train_label, eval_input, eval_label = data.load_data()\n",
    "\n",
    "#TODO3: 실행 안됨, 실행 후 지속적으로 리뷰하겠음\n",
    "\n",
    "# 훈련셋 인코딩 만드는 부분이다.\n",
    "train_input_enc, train_input_enc_length = data.enc_processing(train_input, char2idx)\n",
    "# 훈련셋 디코딩 입력 부분 만드는 부분이다.\n",
    "train_output_dec, train_output_dec_length = data.dec_input_processing(train_label, char2idx) #TODO1 실행 안되어 확인 필요(AttributeError: module 'data' has no attribute 'dec_output_processing)\n",
    "# 훈련셋 디코딩 출력 부분 만드는 부분이다.\n",
    "train_target_dec = data.dec_target_processing(train_label, char2idx)\n",
    "\n",
    "# 평가셋 인코딩 만드는 부분이다.\n",
    "eval_input_enc, eval_input_enc_length = data.enc_processing(eval_input,char2idx)\n",
    "# 평가셋 인코딩 만드는 부분이다.\n",
    "eval_output_dec, eval_output_dec_length = data.dec_input_processing(eval_label, char2idx)\n",
    "# 평가셋 인코딩 만드는 부분이다.\n",
    "eval_target_dec = data.dec_target_processing(eval_label, char2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 체크 포인트 경로 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 현재 경로'./'에 현재 경로 하부에 \n",
    "# 체크 포인트를 저장한 디렉토리를 설정한다.\n",
    "check_point_path = os.path.join(os.getcwd(), DEFINES.check_point_path)\n",
    "# 디렉토리를 만드는 함수이며 두번째 인자 exist_ok가 \n",
    "# True이면 디렉토리가 이미 존재해도 OSError가 \n",
    "# 발생하지 않는다.\n",
    "# exist_ok가 False이면 이미 존재하면 \n",
    "# OSError가 발생한다.\n",
    "os.makedirs(check_point_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 에스티 메이터 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에스티메이터 구성한다.\n",
    "\n",
    "# TODO2: 왜 분류모델이라고 적혀있나요???? s2s이 아닌가요?\n",
    "\n",
    "classifier = tf.estimator.Estimator(\n",
    "        model_fn=ml.model, # 모델 등록한다.\n",
    "        model_dir=DEFINES.check_point_path, # 체크포인트 위치 등록한다.\n",
    "        params={ # 모델 쪽으로 파라메터 전달한다.\n",
    "            'hidden_size': DEFINES.hidden_size, # 가중치 크기 설정한다.\n",
    "            'layer_size': DEFINES.layer_size, # 멀티 레이어 층 개수를 설정한다.\n",
    "            'learning_rate': DEFINES.learning_rate, # 학습율 설정한다. \n",
    "            'vocabulary_length': vocabulary_length, # 딕셔너리 크기를 설정한다.\n",
    "            'embedding_size': DEFINES.embedding_size, # 임베딩 크기를 설정한다.\n",
    "            'embedding': DEFINES.embedding, # 임베딩 사용 유무를 설정한다.\n",
    "            'multilayer': DEFINES.multilayer, # 멀티 레이어 사용 유무를 설정한다.\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 실행\n",
    "classifier.train(input_fn=lambda:data.train_input_fn(\n",
    "    train_input_enc, train_output_dec, train_target_dec,  DEFINES.batch_size), steps=DEFINES.train_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 평가 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result = classifier.evaluate(input_fn=lambda:data.eval_input_fn(\n",
    "    eval_input_enc, eval_output_dec, eval_target_dec,  DEFINES.batch_size))\n",
    "print('\\nEVAL set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 테스트 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트용 데이터 만드는 부분이다.\n",
    "# 인코딩 부분 만든다.\n",
    "predic_input_enc, predic_input_enc_length = data.enc_processing([\"가끔 궁금해\"], char2idx)\n",
    "# 학습 과정이 아니므로 디코딩 입력은 \n",
    "# 존재하지 않는다.(구조를 맞추기 위해 넣는다.)\n",
    "predic_output_dec, predic_output_decLength = data.dec_input_processing([\"\"], char2idx)       \n",
    "# 학습 과정이 아니므로 디코딩 출력 부분도 \n",
    "# 존재하지 않는다.(구조를 맞추기 위해 넣는다.)\n",
    "predic_target_dec = data.dec_target_processing([\"\"], char2idx)      \n",
    "\n",
    "# 예측을 하는 부분이다.\n",
    "predictions = classifier.predict(\n",
    "    input_fn=lambda:data.eval_input_fn(predic_input_enc, predic_output_dec, predic_target_dec, DEFINES.batch_size))\n",
    "\n",
    "# 예측한 값을 인지 할 수 있도록 \n",
    "# 텍스트로 변경하는 부분이다.\n",
    "data.pred2string(predictions, idx2char)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
